
[55:00] 高维拟合函数也满足比限逼近定理    


[57:31] # 换个方式     

\\(x\\) 本身一维，考虑到平移，再升一维。　　

隐层的\\(l\\)是指基函数线性组合后整体增加一个平移。   
在这里， std gauss 相当于激活函数。    
连接线上的数值 \\((a_i,b_i,\omega _i)\\)是网络参数。   
\\(n\\)对应网络隐层的结点个数，需要手调。   


[1:03:36] # RBF 神经网络  

RBF 神经网络的问题是，关于 \\(a,b\\) 的导数难求，高阶且非凸，
难以优化。只能找局部最小，因此初值很重要。  


[1:06:09] # 思考   

机器学习的本质是在做拟合。  


[1:08:29] #　高维    

高维只是在输入层，输出层纵向多加几个圈     
共享基函数，使用不同的系数      


[1:11:09] #　多层   

通常每层使用相当的激活函数，方便优化    
增加网络的深度和宽度，都会极大膨胀参数个数    
同样参数量级下，通常深的比宽的好，因为深的自由度更高   

P3 参数曲线   

3.2　#　二元函数[09:50]   

最高为二次，因此只取不超过二次的项。即三角形区域     


[15:38]多元函数的神经网络表达   

神网络方式可以解决张量积方式的维数膨胀问题   
因为100维输的张量积程度是10000维，而神经网络的\\(m\\)可以控制。  