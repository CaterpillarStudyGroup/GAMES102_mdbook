![](../assets/å»ºæ¨¡100.png)    


# Recap: 3D Content Creation    

â€¢ Surface reconstruction    
â€¢ Geometric modeling    
â€¢ Geometry processing    
â€¢ Creative generation    
â€¢ â€¦     


# Analyzing and Understanding 3D Contents    


â€¢ Organize Geometric Data    
â€¢ Understand Structure and Relationships    
â€¢ Understand Semantics and Functionality    
â€¢ Synthesizing New Shapes    
â€¢ â€¦     



# ä¸‰ç»´å‡ ä½•å¤„ç†ï¼šä»å±€éƒ¨åˆ°**å…¨å±€**    




# From lowâ€ to highâ€level processing     

* Local level analysis    
â€¢ purely geometry/contentâ€driven    
â€¢ mathematical formulation of objectives    
â€¢ Examples: curvature and normal estimation, mesh smoothing, simplification, remeshing, parameterizationâ€¦    
* High level analysis    
â€¢ nonâ€local analysis    
â€¢ not easy to formulate objectives mathematically    
â€¢ **Semantics** is hard!    


# Problems of Shape Analysis   


# Understanding Shapes    

* Shape features     
â€¢ Feature points     
â€¢ Feature lines    
â€¢ Saliency    



# Understanding Shapes    

â€¢ Alignment (upright)    



# Understanding Shapes     

â€¢ Shape segmentation (components)    



# Understanding Shapes    

* Coâ€segmentation of a set of shapes     
â€¢ More knowledge can be inferred from multiple shapes rather than an individual shape     


# Understanding Shapes    

â€¢ Labeling    




# Understanding Shapes    

â€¢ Symmetries    




# Understanding Shapes    

â€¢ Skeleton    




# Understanding Shapes    

* Shape matching    
â€¢ Similarity    
â€¢ Correspondences    



# Understanding Shapes   


â€¢ Shape retrieval    





# Understanding Shapes   

â€¢ Classification     




# Understanding Shapes    

â€¢ Structures   
â€¢ Hierarchical structures     



# Understanding Shapes    

â€¢ Functionality    



# Understanding Shapes     

â€¢ Object affordance    



# Understanding Shapes     

* Abstraction of shapes    
â€¢ [Mehra et al. SIGAsia 2009]    


* Understanding assemblies    
â€“ [Mitra et al. SIG 2010]    



# Shape Descriptors    


# æ ¸å¿ƒé—®é¢˜ï¼šå½¢çŠ¶è¡¨å¾ï¼ˆæè¿°å­ã€ç‰¹å¾ï¼‰    
(Shape representation/descriptor/feature)    




# ä¾‹å­ï¼šæ¨¡å‹åˆ†å‰²â€æ ¹æ®ç‰¹å¾çš„èšç±»     
(Clustering/Labeling)    





# ä¸‰ç»´æ•°æ®çš„ä¿¡æ¯    



* ç‚¹åæ ‡(x,y,z)    
* å‡ ä½•é‡    
â€¢ é•¿åº¦ã€è§’åº¦ã€é¢ç§¯ã€ ä½“ç§¯    
* å¾®åˆ†é‡     
â€¢ æ³•å‘é‡    
â€¢ æ›²ç‡     
* æ‹“æ‰‘é‡    
â€¢ è¿æ¥å…³ç³»    
â€¢ Laplaceè°±    
* æ˜ å°„åº¦é‡    
â€¢ é›…å¯æ¯”ï¼ˆå˜å½¢é‡ï¼‰   
â€¢ å…±å½¢æ¯”   
* â€¦    



# Shape Descriptors    


* Shape Descriptors     
â€¢ Fixed dimensional vector    
â€¢ Independent of model representation    
â€¢ Easy to match     




# Shape Descriptors    

* Representation:    
â€¢ **What can you represent**?    
â€¢ What are you representing?    
* Matching:    
â€¢ How do you align?   
â€¢ Part or whole matching?    





# Shape Descriptors    

* Representation:    
â€¢ What can you represent?    
â€¢ What are you representing?    


* Matching:    
â€¢ How do you align?    
â€¢ Part or whole matching?    




# Shape Descriptors    

* Representation:    
â€¢ What can you represent?    
â€¢ What are you representing?    



* Matching:    
â€¢ **How do you align**?    
â€¢ Part or whole matching?   





How do you represent models across the space of 
transformations that donâ€™t change the shape?



# Shape Descriptors    


* Representation:    
â€¢ What can you represent?    
â€¢ What are you representing?    


* Matching:   
â€¢ How do you align?   
â€¢ Part or whole matching?   


Can you match part of a shape to the 
whole shape?


# Extended Gaussian Image     
[Horn, 1984]    


â€¢ Represent a model by a spherical function by binning 
surface normals      




# Extended Gaussian Image    
[Horn, 1984]

* Properties:    
â€¢ Invertible for convex shapes    
â€¢ 2D array of information    
â€¢ Can be defined for most models    
* Limitations:    
â€¢ Too much information is lost    
â€¢ Normals are sensitive to noise    



# Shape Histograms    
[Ankerst et al., 1999]   

â€¢ Shape descriptor stores a histogram of how much surface resides at different bins in space    




# Gaussian Euclidean Distance Transform    
[Kazhdan et al., 2003]


â€¢ The value at a point is obtained by summing the Gaussian of the closest point on the model surface.    
> &#x2705; Distributes the surface into adjacent bins    
> &#x2705;Maintains highâ€frequency information    





# Spherical Extent Function    
[Vranic et al. 2002]

â€¢ For every view direction, store the distance to the first 
point a viewer would see when looking at the origin.    




# Spherical Extent Function    

* A model is represented by its starâ€shaped envelope:
â€¢ The minimal surface containing the model with the property that the center sees every point on the surface    
â€¢ Transforms arbitrary genus models to genusâ€0 surfaces    








# Spherical Extent Function    

* Properties:    
â€¢ Can be defined for most models    
â€¢ Invertible for starâ€shaped models    
â€¢ 2D array of information    
* Limitations:    
â€¢ Distance only measures angular proximity    


# Light Field Descriptor    
[Chen et al. 2003]    


â€¢ For every view direction, store the image the viewer 
would see when looking at the origin.    



# Light Field Descriptor    

â€¢ Hybrid boundary/volume representation    



# Light Field Descriptor    

 - Properties:    
    - Can be defined for most models    
    - Invertible for starâ€shaped models    
    - 4D array of information    
    - Similarity = sum of area and contour similarities    
      - There is a well defined interior    
      - Can parameterize contours in 2D     



      

# å„ç§äººå·¥å®šä¹‰çš„3Då½¢çŠ¶ç‰¹å¾    







# Methodology    

# Traditional Methods     



# ç‰¹å¾å·¥ç¨‹çš„ä¸¤ä¸ªä¸»è¦é—®é¢˜    





# å¦‚ä½•é€‰æ‹©åˆé€‚çš„ç‰¹å¾ï¼Ÿ   





# æƒ³æ³•ï¼šç¨€ç–å­¦ä¹ é€‰æ‹©åˆé€‚çš„ç‰¹å¾    
[Hu et al. SGP 2012]    



â€¢ ç¨€ç–å­¦ä¹ çš„æœ¬è´¨ï¼šèšç±»    
â€¢ å­ç©ºé—´èšç±»(Subspace clustering)    




# Subspace Clustering     
[Vidal 2010]    


* Input: 
â€¢ high dimensional datasets having low intrinsic dimensions
â€¢ {\\(x_j\\)}\\(_{j=1,â€¦,N,}x_t âˆˆ â„^D\\)
 

* Output:    
â€“ multiple lowâ€dimensional linear subspaces    
â€“ ğ¿, \\(ğ‘ƒ_1, ğ‘ƒ_2\\)   



# Formulation: Group Lasso    

* Our solution:
â€¢ apply subspace clustering in each feature space
â€¢ add the <u>consistent multiâ€feature penalty<\u>      


$$
\underset{W_{1}, \ldots, W_{H}}{\min} \quad \sum_{h=1}^H \mathcal{F}(W_{h})+P_{\text {cons }}\left(W_{1}, W_{2}, \ldots, W_{H}\right)
$$ 

$$
s.t.  \quad W_h \ge 0, \operatorname{diag}(W_{h})=0, \quad h=1,2, \ldots, H
$$

$$
where \quad \mathcal {F} (W_h) =||X_h W_h-X_h||_{F}^{2}+ \lambda||W_{h}^{T} W_{h}||_{1,1} 
$$

$$
where \quad \mathcal {F} (W_h) =||X_h W_h-X_h||_{F}^{2}+ \lambda
$$

$$
||W_{h}^{T} W_{h}||_{1,1} 
$$



# Consistent multiâ€feature penalty    


1. Find the most similar patch pairs 
2. Corresponding patches need not be similar in all features   



ğ‘ƒà¯–à¯¢à¯¡à¯¦
ğ‘Šà¬µ, ğ‘Šà¬¶,â€¦,ğ‘Šà¯ àµŒ Î±
ğ‘Š à¬¶,à¬µ àµ… ğ›½
ğ‘Š à¬µ,à¬µ
ğ‘Š àµŒ 
áˆºğ‘Šà¬µ
áˆ»à¬µà¬µ áˆºğ‘Šà¬µ
áˆ»à¬µà¬¶ â€¦ áˆºğ‘Šà¬µ
áˆ»
à¯‡
à°®
áˆºğ‘Šà¬¶
áˆ»à¬µà¬µ áˆºğ‘Šà¬¶
áˆ»à¬µà¬¶ â€¦ áˆºğ‘Šà¬¶
áˆ»
à¯‡
à°®
â‹®
áˆºğ‘Šà¯
áˆ»à¬µà¬µ
â‹®
áˆºğ‘Šà¯
áˆ»à¬µà¬¶
â‹±
â€¦
â‹®
áˆºğ‘Šà¯
áˆ»
à¯‡
à°®
Results
Deep Learning based Methods
Handâ€crafted Features are not Enough
â€¢ â€œHandâ€craftedâ€ feature descriptor need domain 
knowledge
â€¢ Too many feature descriptor, which is the best
?
â€¢ Concatenation of the features may result in overâ€
fitting in feature space
Use deep leaning to extract 
good feature descriptors!
æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼šç«¯åˆ°ç«¯
äººå·¥è®¾è®¡
ç‰¹å¾
Tasks
å­¦ä¹ 
ç‰¹å¾
Tasks
ä¼ ç»Ÿå­¦ä¹ æ–¹æ³•
æ·±åº¦å­¦ä¹ æ–¹æ³•
Deep Neural Networks (DNN)
Regression problem:
Input: Given training set (x
1, y
1), (x
2, y
2), (x
3, y3 ), â€¦. 
Output: Adjust parameters 
ï± (for every node) to make: 
à¯œ
à¯œ
ä¸‰ç»´æ•°æ®çš„æ·±åº¦å­¦ä¹ çš„ä¸‰ç§æ–¹æ³•
å…³äºæ·±åº¦å­¦ä¹ 
â€¢ é€šç”¨æ‹Ÿåˆå™¨ï¼ˆè¾ƒå¤§çš„é€¼è¿‘å‡½æ•°ç©ºé—´ï¼‰
â€¢ åº”ç”¨ä¸‰éƒ¨æ›²
â€¢ åœ¨å“ªæ‰¾ï¼ˆç½‘ç»œæ„é€ ï¼‰ã€å“ªä¸ªå¥½ï¼ˆæŸå¤±å‡½æ•°ï¼‰ã€æ€ä¹ˆæ‰¾ï¼ˆä¼˜åŒ–ï¼‰
â€¢ ä»…æ‹Ÿåˆäº†å¤§é‡æ ·æœ¬ï¼šå¯èƒ½åªæ˜¯â€œè™šå‡å…³ç³»â€
â€¢ å¹¶æ²¡æœ‰â€œç†è§£â€æˆ–â€œè®¤çŸ¥â€çœŸæ­£çš„è§„å¾‹
â€¢ ä¸å¯è§£é‡Šæ€§
â€¢ æ€§èƒ½ä¾èµ–è®­ç»ƒæ ·æœ¬ï¼ˆæ•°æ®é›†ï¼‰
â€¢ å½“æ•°æ®é›†è¶³å¤Ÿå¯†ï¼šè¿‘ä¼¼â€œæœ€è¿‘é‚»â€ç®—æ³•
â€¢ è®­ç»ƒæ•°æ®é›†ä¸å¤Ÿå®Œå¤‡ï¼šç¼ºä¹æ³›åŒ–èƒ½åŠ›
â€¢ å¤§éƒ¨åˆ†æ˜¯è¿‡æ‹Ÿåˆ
â€¢ åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„æ·±åº¦å­¦ä¹ å¹¶ä¸æ˜¯çœŸæ­£çš„AIï¼Œç¦» çœŸæ­£çš„â€œæ™ºèƒ½â€ä»å¾ˆé¥è¿œ
ç¨€ç–å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ ï¼šæ®Šé€”åŒå½’
â€¢ æ–¹æ³•çš„ä¸åŒæ€§
â€¢ å‹ç¼©æ„ŸçŸ¥ï¼šåŸºäºæ¨¡å‹çš„ï¼Œæœ‰å¾ˆå¥½çš„ç»“æ„å’Œæ•°å­¦æ¨¡å‹ï¼›
æ¥è‡ªäºæ•°å­¦ç†è®ºçš„çªç ´
â€¢ æ·±åº¦å­¦ä¹ ï¼šåŸºäºå®è¯çš„ï¼Œæ¨¡å‹çµæ´»ï¼Œé¡»é€šè¿‡æ•°æ®è¿›è¡Œ
ç›‘ç£å­¦ä¹ ï¼›æ¥è‡ªäºæ±‚è§£é€Ÿåº¦çš„çªç ´
â€¢ ä¸€è‡´æ€§
â€¢ ç›®æ ‡ï¼šé«˜ç»´æ•°æ®çš„ä¿¡æ¯(ç‰¹å¾)æå–
â€¢ ç»“æœï¼šä»å±€éƒ¨ä¿¡æ¯æ¥å¤„ç†å…¨å±€ä¿¡æ¯
â€¢ ç±»ä¼¼çš„ç½‘ç»œç»“æ„ï¼šæ±‚è§£L1ä¼˜åŒ–çš„IST (Iterative Softâ€
Thresholding)ç®—æ³•å®è´¨ä¸Šæ˜¯å¤šå±‚ç½‘ç»œä¼˜åŒ–
Trends
3D Data: Big Data Era?
Crossâ€Domain ï¼ˆè·¨æ¨¡æ€ï¼‰
å¤šæ¨¡æ€
Creative Design
â€¢ How can computational tools support human creativity?
â€¢ â€“What stimulates creative design?
â€¢ â€“How can computers help?
â€¢ â€“Requires something more than just structural/functional/semantic 
analysis of shapes
â€¢ 3D content creation is still far from solved!
è°¢ è°¢ï¼
